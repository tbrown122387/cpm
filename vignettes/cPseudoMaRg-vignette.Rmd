---
title: "Using cPseudoMaRg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{cPseudoMaRg-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: bibliography.bib
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## What does this package provide?

This package provides the boilerplate code for the correlated pseudo-marginal method of [@cpm]. This vignette demonstrates its use by providing two examples that are closely related to ones given in the above paper. 

## What do I need to know to use this software?

Before getting to the examples, however, I provide a more detailed description of this package's primary function: `makeCPMSampler()`. This is a *function factory* in that it is function that creates and returns a function. Many of `makeCPMSampler()`'s required arguments are functions, as well. 

To use this package, you will have to be somewhat familiar with Metropolis-Hasting's-type algorithms. Here is an extremely short description of how these work. 

Assume that you are a Bayesian and have some data $y$, and that you would like to perform inference for a collection of parameters $\theta$. After specifying a likelihood ($p(y \mid \theta)$) and a prior ($p(\theta)$), you are interested in sampling from the posterior $p(\theta \mid y)$ using a Metropolis-Hastings-type algorithm. Such an algorithm will draw correlated samples $\theta^1, \theta^2, \ldots, \theta^{N_{S}}$ from a Markov chain, and under suitable regularity conditions, the average of your large collection of samples will approximate posterior expectations such as the posterior mean: $E[\theta \mid y]$.

Metropolis-Hastings type algorithms will generate the Markov sequence in a clever way. But you still need to provide a few things. One of the things you need to provide is a (well-tuned) proposal transition distribution. This is what proposes new parameters from old. Some of these proposals will be accepted, and others won't. You will need to be able to sample from this function, and to evaluate it. You provide it to `logLikeApproxEval()` in the first two arguments: `paramKernSamp` and `logParamKernEval`.

Recall that your specified model has a likelihood and a prior. You will need to provide a function that evaluates the (log of the) prior. This is the third argument: `logPriorEval`. 

Unlike the standard Metropolis-Hastings algorithm, you will not be required to provide a function that evaluates the likelihood. Recall that this function provides a  pseudo-marginal sampler, TODO cite, so you are only required to give an unbiased estimate of the likelihood. This is provided as the fourth argument: `logLikeApproxEval`.^[If you'd like, you may provide for this argument a function giving exact evaluations. In this case, `makeCPMSampler()` will return a standard MH sampler. This can be useful if you are comparing the relative efficiency of pseudo-marginal and non-pseudo-marginal methods.]

Finally, you must provide the non-functional arguments. `yData` is the entire data set of observations. `numU` is the number of standard univariate normal samples that are used for each approximate log-likelihood evaluation. `numIters` is the total number of samples drawn. This does not count burn-in or thinning. `rho` is the correlation between standard normal variates at each MCMC iteration. Finally, change `storeEvery` to some integer greater than $1$ if you are concerned about memory on your computer, and you'd like to use thinning. If you set it to $2$, say, then every other sample will be retained.


## A First Example

The first example is the same as the provided in TODO's documentation. This section breaks up the code into chunks in order to explain it more easily. The model has two parameters: $\theta = (\theta_1, \theta_2)$. The conditional likelihood is


$$
\begin{eqnarray} 
p(y_{1:N} \mid x_{1:N}, \theta) = \prod_{i=1}^N p(y_{i} \mid x_{i}, \theta) 
\end{eqnarray}
$$
where
$$
\begin{eqnarray} 
y_{i} \mid x_{i}, \theta \sim \text{Normal}(x_i, \theta_1 - \theta_2).
\end{eqnarray}
$$
Here $x_1, \ldots, x_N := x_{1:N}$ is a collection of latent/hidden/unobserved random variables. They have the following distribution:

$$
\begin{eqnarray} 
p(x_{1:N} \mid \theta) = \prod_{i=1}^N p( x_{i} \mid \theta) 
\end{eqnarray}
$$

where

$$
\begin{eqnarray} 
x_{i} \mid  \theta \sim \text{Normal}(x_i, \theta_2)
\end{eqnarray}.
$$

We can simulate $10$ observations with the following code. 

```{r, collapse = TRUE, echo=FALSE}
realTheta1 <- .2 + .3
realTheta2 <- .2
realParams <- c(realTheta1, realTheta2)
numObs <- 10
realX <- rnorm(numObs, mean = 0, sd = sqrt(realTheta2))
realY <- rnorm(numObs, mean = realX, sd = sqrt(realTheta1 - realTheta2))
```

Next, construct the sampler function using `makeCPMSampler()`.

```{r, collapse=TRUE}
library(cPseudoMaRg)
numImportanceSamps <- 1000
numMCMCIters <- 1000
randomWalkScale <- 1.5
recordEveryTh <- 1
sampler <- makeCPMSampler(
  paramKernSamp = function(params){
    return(params + rnorm(2)*randomWalkScale)
  },
  logParamKernEval = function(oldTheta, newTheta){
    dnorm(newTheta[1], oldTheta[1], sd = randomWalkScale, log = TRUE)
    + dnorm(newTheta[2], oldTheta[2], sd = randomWalkScale, log = TRUE)
  },
  logPriorEval = function(theta){
    if( (theta[1] > theta[2]) & all(theta > 0)){
      0
    }else{
      -Inf
    }
  },
  logLikeApproxEval = function(y, thetaProposal, uProposal){
    if( (thetaProposal[1] > thetaProposal[2]) & (all(thetaProposal > 0))){
      xSamps <- uProposal*sqrt(thetaProposal[2])
      logCondLikes <- sapply(xSamps,
                             function(xsamp) {
                               sum(dnorm(y,
                                         xsamp, 
                                         sqrt(thetaProposal[1] - thetaProposal[2]),
                                         log = TRUE)) })
      m <- max(logCondLikes)
      log(sum(exp(logCondLikes - m))) + m - log(length(y))
    }else{
      -Inf
    }
  },
  realY, 
  numImportanceSamps, 
  numMCMCIters, 
  .99, # change to 0 for original pseudo-marginal method
  recordEveryTh)
```

The approximate log-likelihood, provided to `logLikeApproxEval`, uses importance sampling (TODO cite). 

$$
\begin{align*} 
\log \hat{p}(y_{1:N} \mid  \theta) 
&= \log \left\{ 
N^{-1} \sum_{i=1}^N \frac{p(y_{1:N} \mid x_{1:N}, \theta) p(x_{1:N} \mid \theta)}{q(x_{1:N} \mid y_{1:N}, \theta)}
\right\}
\end{align*}
$$
We choose $q(x_{1:N} \mid y_{1:N}, \theta) = p(x_{1:N} \mid \theta)$, despite it not being the optimal proposal/instrumental distribution. Note the use of the "log-sum-exp" trick to avoid numerical underflow TODO cite.

Finally, sample the Markov chain. Call the samples `res`, and examine them. 

```{r, collapse=TRUE, out.width='80%',}
res <- sampler(realParams)
print(res)
plot(res)
```

This particular model has a tractable likelihood, so it is more efficient to use regular MH. It is equal to the following

$$
\begin{align*} 
p(y_{1:N} \mid  \theta) 
&= \int p(y_{1:N} \mid x_{1:N}, \theta) p(x_{1:N} \mid \theta) \text{d}x_{1:N} \\
&= \prod_{i=1}^N \text{Normal}(y_i ; 0, \theta_1)
\end{align*}
$$


```{r, collapse=TRUE, out.width='80%',}
samplerExact <- makeCPMSampler(
  paramKernSamp = function(params){
    return(params + rnorm(2)*randomWalkScale)
  },
  logParamKernEval = function(oldTheta, newTheta){
    dnorm(newTheta[1], oldTheta[1], sd = randomWalkScale, log = TRUE)
    + dnorm(newTheta[2], oldTheta[2], sd = randomWalkScale, log = TRUE)
  },
  logPriorEval = function(theta){
    if( (theta[1] > theta[2]) & all(theta > 0)){
      0
    }else{
      -Inf
    }
  },
  logLikeApproxEval = function(y, thetaProposal, uProposal){
    # this is exact now!
    if( (thetaProposal[1] > thetaProposal[2]) & (all(thetaProposal > 0))){
      sum(dnorm(y, mean = 0, sd = sqrt(thetaProposal[1]), log = TRUE))
    }else{
      -Inf
    }
  },
  realY, 
  numImportanceSamps, # doesn't this matter because Us are not used
  numMCMCIters, 
  .99, # doesn't this matter because Us are not used
  recordEveryTh)
res2 <- samplerExact(realParams)
print(res2)
plot(res2)
```

# References
